{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_dict = {\n",
    "    'bank':[\n",
    "        'BBVA BANCOMER',\n",
    "        'BANORTE',\n",
    "        'SANTANDER',\n",
    "        'BANCO NACIONAL DE MEXICO',\n",
    "        'BANREGIO',\n",
    "        'BANAMEX',\n",
    "        'HSBC',\n",
    "        'BANCO AFIRME',\n",
    "        'BANCO AZTECA',\n",
    "        'BANCOPPEL',\n",
    "        'SCOTIABANK',\n",
    "        'BANCO REGIONAL DE MONTERREY',\n",
    "        'BANCO DEL BAJIO',\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "\n",
    "# Ingeniería de variables\n",
    "from numpy import nan\n",
    "from re import sub, UNICODE\n",
    "from unicodedata import normalize\n",
    "from datetime import datetime, date\n",
    "from difflib import get_close_matches\n",
    "from pandas import DataFrame, read_csv, to_datetime\n",
    "\n",
    "class ShoppersChurn:\n",
    "    def __init__(self, file_name: str='raw_data_MTY', correct_dict: Dict=correct_dict) -> None:\n",
    "        self.correct_dict = correct_dict\n",
    "        self.base_dir = Path.cwd().parent\n",
    "        self.data_dir = self.base_dir.joinpath('data')\n",
    "        self.file_name = file_name\n",
    "        self.file_path = self.data_dir.joinpath(f'{self.file_name}.csv')\n",
    "        if not self.file_path.is_file():\n",
    "            print(f'There should be a file called \"{self.file_name}\" at:\\n{self.data_dir}\\n\\nAdd it and try again!')\n",
    "\n",
    "\n",
    "    def get_files(self, shopper_id_col: str='shopper_id') -> None:\n",
    "        data = read_csv(self.file_path, low_memory=False)\n",
    "        end_of_shopper_data = [x for x,y in enumerate(data.columns) if y=='end_of_shoppers_data'][0]\n",
    "        self.sh = data.iloc[:,:end_of_shopper_data].drop_duplicates(shopper_id_col)\n",
    "        self.df = data[[shopper_id_col]].join(data.iloc[:,end_of_shopper_data+1:])\n",
    "\n",
    "\n",
    "    def clean_text(self, text: str, pattern: str=\"[^a-zA-Z0-9\\s]\", lower: bool=False) -> str: \n",
    "        '''\n",
    "        Limpieza de texto\n",
    "        '''\n",
    "        # Reemplazar acentos: áàäâã --> a\n",
    "        clean = normalize('NFD', str(text).replace('\\n', ' \\n ')).encode('ascii', 'ignore')\n",
    "        # Omitir caracteres especiales !\"#$%&/()=...\n",
    "        clean = sub(pattern, ' ', clean.decode('utf-8'), flags=UNICODE)\n",
    "        # Mantener sólo un espacio\n",
    "        clean = sub(r'\\s{2,}', ' ', clean.strip())\n",
    "        # Minúsculas si el parámetro lo indica\n",
    "        if lower: clean = clean.lower()\n",
    "        # Si el registro estaba vacío, indicar nulo\n",
    "        if clean in ('','nan'): clean = nan\n",
    "        return clean\n",
    "\n",
    "\n",
    "    def choose_correct(self, df: DataFrame, col: str, correct_list: list, fill_value: str='Otro', keep_nan: bool=True, replace_col: bool=True, **kwargs) -> DataFrame:\n",
    "        '''\n",
    "        Recibe un DataFrame y una lista de posibilidades, especificando la columna a revisar\n",
    "        elige la opción que más se parezca a alguna de las posibilidades\n",
    "        '''\n",
    "        # Aplicar limpieza de texto a la lista de posibilidades\n",
    "        correct_clean = list(map(lambda x: self.clean_text(x, lower=True), correct_list))+['nan']\n",
    "        # Hacer un diccionario de posibilidades limpias y las originales recibidas\n",
    "        correct_dict = dict(zip(correct_clean, correct_list+['nan']))\n",
    "\n",
    "        # Aplicar la limpieza a la columna especificada\n",
    "        df[f'{col}_correct'] = df[col].map(lambda x: self.clean_text(x,lower=True))\n",
    "        # Encontrar las posibilidades más parecidas\n",
    "        df[f'{col}_correct'] = df[f'{col}_correct'].map(lambda x: get_close_matches(str(x), correct_clean, **kwargs))\n",
    "        # Si existen parecidas, traer la primera opción que es la más parecida\n",
    "        df[f'{col}_correct'] = df[f'{col}_correct'].map(lambda x: x[0] if isinstance(x,list) and len(x)>0 else nan)\n",
    "        # Regresar del texto limpio a la posibilidad original, lo no encontrado se llena con \"fill_value\"\n",
    "        df[f'{col}_correct'] = df[f'{col}_correct'].map(correct_dict).fillna(fill_value)\n",
    "        \n",
    "        if keep_nan: df[f'{col}_correct'] = df[f'{col}_correct'].map(lambda x: nan if str(x)=='nan' else x)\n",
    "        if replace_col: df = df.drop(col, axis=1).rename({f'{col}_correct':col}, axis=1)\n",
    "        return df\n",
    "\n",
    "\n",
    "    def clean_shopper_data(self, marital_col: str='marital_status', insurance_col: str='insurance', bank_col: str='bank', transport_col: str='transport') -> None:\n",
    "        df = self.sh.copy()\n",
    "        df[marital_col] = df[marital_col].map(lambda x: nan if str(x)=='nan' else x.replace(' ',''))\n",
    "\n",
    "        aux = []\n",
    "        for x in df[insurance_col]:\n",
    "            if str(x)=='nan': aux.append(nan)\n",
    "            else: \n",
    "                try: to_append = to_datetime(x, format=r'%d/%m/%y')\n",
    "                except: \n",
    "                    try: to_append = to_datetime(x[:10], format=r'%Y-%m-%d')\n",
    "                    except: \n",
    "                        try: to_append = to_datetime(x[:11], format=r'%d-%b-%Y')\n",
    "                        except: to_append = nan\n",
    "                finally: aux.append(to_append)\n",
    "        df[insurance_col] = aux\n",
    "\n",
    "        df = self.choose_correct(df, bank_col, self.correct_dict[bank_col], n=1, cutoff=0.7)\n",
    "\n",
    "        df[transport_col] = df[transport_col].map(lambda x: nan if str(x)=='nan' else x.split()[0].title())\n",
    "        aux = df[transport_col].value_counts(1).to_frame()\n",
    "        self.correct_dict[transport_col] = [x for x,y in zip(aux.index, aux[transport_col]) if y>=0.02]\n",
    "        df = self.choose_correct(df, transport_col, self.correct_dict[transport_col], n=1, cutoff=0.7)\n",
    "\n",
    "        self.sh = df.copy()\n",
    "        \n",
    "    def vars_shopper(self, id_col: str='shopper_id', official_id_col: str='official_id', insurance_col: str='insurance', add_drop_cols: list=['last_date']) -> None:\n",
    "        df = self.sh.set_index(id_col)\n",
    "\n",
    "        df['birthday'] = to_datetime(df[official_id_col].str[4:10], format=r'%y%m%d')\n",
    "        df['birthday'] = df['birthday'].map(lambda x: date(x.year-100, x.month, x.day) if x.year>datetime.today().year else x)\n",
    "        df['age_in_days'] = (datetime.today() - df['birthday']).dt.days\n",
    "\n",
    "        df['genre'] = df[official_id_col].str[10:11]\n",
    "\n",
    "        df['days_for_insurance_exp'] = df[insurance_col].map(lambda x: nan if str(x)=='nan' else (x - datetime.today()).days)\n",
    "        \n",
    "        df.drop([official_id_col, 'birthday', insurance_col]+add_drop_cols, axis=1, inplace=True)\n",
    "\n",
    "        self.shop_num_cols = df.sample(frac=0.01).describe().columns\n",
    "        self.shop_cat_cols = [x for x in df.columns if x not in self.shop_num_cols]\n",
    "        self.sh = df.copy()\n",
    "\n",
    "sc = ShoppersChurn()\n",
    "sc.get_files()\n",
    "sc.clean_shopper_data()\n",
    "sc.vars_shopper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickings_vs_deliveries', 'completed_deliveries', 'completed_pickings',\n",
       "       'completed_pickings_score', 'rating', 'accepted_rate',\n",
       "       'accepted_rate_score', 'fulfillment_rate', 'picking_speed',\n",
       "       'late_minutes_score', 'refund_post_sales_score', 'replacements_score',\n",
       "       'call_chat_score', 'score', 'age_in_days', 'days_for_insurance_exp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.shop_num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b242a032645bafbbcb1166ddc12c6be26fce6a9e64135cb292f5e9ea8c9202a8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
